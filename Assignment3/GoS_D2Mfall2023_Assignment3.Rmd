---
title: 'D2M Fall 2023: Assignment 3'
output:
  html_document:
    df_print: paged
---

This is a completed assignment for Professor Hurst of Data Manuscript 
```{r, error=TRUE}
#this is just to give you an example of the code chunk header above, which is only necessary if you're submitting an assignment with code that won't run.
#for example, you might want to do that if you've made some progress on a problem, but aren't able to fully complete it. Rather than submitting nothing, submit what you've done so far. 
```



# Problem 1

Include a chunk at the beginning of your document that loads the tidyverse. Load any other packages you decide to use in the same code-chunk. 
```{r}
library(tidyverse)
```


# Problem 2

For this problem, let's get our data set up to visualize. You'll use a lot of the functions we went over when talking about tidyr and dplyr. It contains five parts. 

We will use data from this paper: https://doi.org/10.1016/j.cogdev.2022.101214

1. Read the abstract to have some understanding of the research questions, tasks, and findings. If you need additional information about the data or the study, you can read the full paper, read the OSF page (https://osf.io/cv763/) or look through the data codebook (https://osf.io/4m7j9)

Dataset 1 includes children's counting behavior: https://osf.io/2p9dx
Dataset 2 includes children's performance on a separate judgement task about the meaning of the words before and after: https://osf.io/k7j8t

Download both datasets and put them in your working directory in a sub-folder called "datasets". Load both CSV files separately and store them as objects. 

In both files, the data is from the same subjects and the linking identifier is called "SubID".

2. Counting task data ("BABSYN_counting_tidy.csv"): this file includes every child's response on every trial on a battery of counting assessments. The battery of tasks included several sub-tasks (indicated by the "Task" column, such as backward counting, forward counting, etc). Create a summary tibble that includes the proportion of trials each child got correct across all trials (regardless of which subtask they came from). Whether or not the child got the trial correct is recorded in the accuracy column (1 = correct, 0 = incorrect). Only include data from children whose data should be included (i.e., where the Include variable is equal to 1). You should end up with one row per child  

3. Ordinal/Magnitude Judgement Task data (BABSYN_YNtask_tidy.csv): this file includes children's responses on every trial of the Ordinal/Magnitude judgement task. Children were given a phrase (e.g., does 5 come after 7?) and asked to make yes or no judgements. We manipulated the order of the numbers (e.g., 5 come after 7 vs. 7 come after 5), the distance between the numbers (i.e., 5 vs 7 or 6 vs 7), and whether we asked about before, after, smaller, or bigger. Create a summary tibble that presents the proportion of trials each child got correct (indicated using the Response.corr column), separated by: (1) whether the word was about order (i.e., before/after) or magnitude (i.e., smaller/bigger) (hint: to do this, you'll want to create a new column that corresponds to these two categories), (2) whether the number being asked about is on the "correct" (aka "same") or opposite side of the target number (indicated using the "Side" column), and (3) whether the numbers are consecutive or non-consecutive (indicated using the TrialType column). Filter so that only children with include == 1 are included. You should end up with a tibble with 8 rows per subject.

4. Combine the two summarized tibbles together so that you end up with the following columns and eight rows per participant:
SubID
ComparisonCategory (or whatever you called your new variable from sub-part 3)
Side
TrialType
PropCorrYNTask (or whatever you called this summary variable)
PropCorrCounting (or whatever you called this summary variable)

5. Provide a one or two sentence explanation for why the PropCorrCounting variable repeats the same value for every row within a given participant, but the other variables do not. 
```{r}
counting <- read.csv("BABSYN_counting_tidy.csv")
task_data <- read.csv("BABSYN_YNtask_tidy.csv")

```

```{r}
counting_summary <- counting %>%
  filter(Include == 1) %>%  # Filter data for children with Include variable equal to 1
  group_by(SubID) %>%
  summarize(PropCorrCounting = mean(accuracy))
```

```{r}

task_summary <- task_data %>%
  filter(Include == 1) %>%
  mutate(ComparisonCategory = case_when(
    grepl("Before|After", Comparison) ~ "Order",
    grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
    TRUE ~ NA_character_
  )) %>%
  mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
  mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
  group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
  summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))




```
```{r}
glimpse(task_summary)
```

```{r}
combined_summary <- counting_summary %>%
  inner_join(task_summary, by = "SubID")
```
```{r}
# PropCorrCounting repeats because it presents the proportion of correct responses in the counting task-- remains constant for that participant.
```


# Problem 3

Hypothesis: children's overall counting score and overall score on the order/magnitude judgement task are linearly correlated. 

Note: remember that the dataset right now (from Problem 2) includes eight rows per participant, for each subtype of the YN task (i.e., the Order/Magnitude judgement task). Before visualizing, summarize the data to create an overall score by taking the average proportion correct across all eight sub-tasks. 

Create a data visualization to explore the hypothesis above. Include:
- at least two geoms
- informative titles for the overall plot and the x and y axis
- meaningful axis limits
- three additional non-data based visual modifications

From the visual alone, do you think the hypothesis is supported? What kind of pattern do you see in the data?

```{r}
# Calculate the overall counting score
counting_summary <- counting %>%
  filter(Include == 1) %>%
  group_by(SubID) %>%
  summarize(PropCorrCounting = mean(accuracy))

# Calculate the overall task score
task_summary <- task_data %>%
  filter(Include == 1) %>%
  mutate(ComparisonCategory = case_when(
    grepl("Before|After", Comparison) ~ "Order",
    grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
    TRUE ~ NA_character_
  )) %>%
  mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
  mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
  group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
  summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))

# Merge the datasets based on 'SubID'
merged_data <- counting_summary %>%
  inner_join(task_summary, by = "SubID")

# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask)) +
  geom_point(color = "blue", size = 3) +  # Scatter plot points
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
  labs(
    title = "Correlation Between Counting Score and Task Score",
    x = "Overall Counting Score",
    y = "Overall Task Score"
  ) +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "none"
  )


```

- I see a positive linear relationship as it looked like it's going upward-- the red linear regression reinforces this. 
# Problem 4

Take your code from Problem 3, and modify it so that you now plot the data for the Order task (i.e., before/after) and the Magnitude task (i.e., Bigger/Smaller) separately (hint: you'll need to use the new column you created for Problem 2). Do this in two ways: (1) within the same plot and (2) as separate faceted plots. 

Which approach do you like better and why? (just one or two sentences is fine)
What do you notice about the data when plotted this way? Make two observations. 

```{r}
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask, color = ComparisonCategory)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Correlation Between Counting Score and Task Score",
    x = "Overall Counting Score",
    y = "Overall Task Score"
  ) +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

```
```{r}
# Create separate faceted plots for Order and Magnitude tasks
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask, color = ComparisonCategory)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Correlation Between Counting Score and Task Score",
    x = "Overall Counting Score",
    y = "Overall Task Score"
  ) +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  facet_wrap(~ComparisonCategory)

```
- For me, I like the separate plots because it is easier to discern the differences
- There is some variability in the data and the correlation is not perfectly linear
# Problem 5

Result: When the numbers are on the correct side (i.e., when Side == "same"), children do better on consecutive numbers, compared to non-consecutive numbers when asked about order (i.e., bigger and smaller), but not when asked about magnitude (i.e., larger and smaller). 

Create a data visualizion to communicate the pattern described above (hint: the hypothesis is only about trials where SIde == "same", so filter your data to focus on those). Include:
- at least three geoms (at least one central tendency statistic and one display of distributional information)
- informative titles for the overall plot and the x and y axis
- meaningful axis limits
- three additional non-data based visual modifications

```{r}
sameside_data <- task_summary %>%
  filter(SideCategory == "Same")

# Create a data visualization to communicate the pattern
ggplot(sameside_data, aes(x = TrialCategory, y = PropCorrYNTask)) +
  geom_boxplot(fill = "grey", color = "blue", width = 0.6, outlier.shape = NA) +
  geom_jitter(position = position_jitter(width = 0.2), color = "blue", size = 3) +
  stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
  labs(
    title = "Task Performance Pattern for Same Side Trials",
    x = "Trial Type",
    y = "Proportion Correct (Mean)"
  ) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```





