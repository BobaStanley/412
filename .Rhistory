View(counting)
View(counting_summary)
# Calculate the overall score by taking the average proportion correct across all eight sub-tasks
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarise(OverallCountingScore = mean(PropCorrCounting, na.rm = TRUE))
# Calculate the overall score by taking the average proportion correct across all eight sub-tasks
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarise(OverallCountingScore = mean(PropCorrCounting, na.rm = TRUE))
View(counting_summary)
# Calculate the overall score by taking the average proportion correct across all eight sub-tasks
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarise(OverallCountingScore = mean(Counting, na.rm = TRUE))
# Calculate the overall score from the "task_summary" dataset
task_summary <- task_data %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarise(OverallTaskScore = mean(PropCorrYNTask, na.rm = TRUE))
View(task_data)
task_summary <- task_data %>%
filter(Include == 1) %>%
mutate(ComparisonCategory = case_when(
grepl("Before|After", Comparison) ~ "Order",
grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
TRUE ~ NA_character_
)) %>%
mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))
counting_summary <- counting %>%
filter(Include == 1) %>%  # Filter data for children with Include variable equal to 1
group_by(SubID) %>%
summarize(PropCorrCounting = mean(accuracy))
# Calculate the overall counting score
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarize(PropCorrCounting = mean(accuracy))
# Calculate the overall task score
task_summary <- task_data %>%
filter(Include == 1) %>%
mutate(ComparisonCategory = case_when(
grepl("Before|After", Comparison) ~ "Order",
grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
TRUE ~ NA_character_
)) %>%
mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))
# Merge the datasets based on 'SubID'
merged_data <- counting_summary %>%
inner_join(task_summary, by = "SubID")
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask)) +
geom_point(color = "blue", size = 3) +  # Scatter plot points
geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
legend.position = "none"
)
# Calculate the overall counting score
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarize(PropCorrCounting = mean(accuracy))
# Calculate the overall task score
task_summary <- task_data %>%
filter(Include == 1) %>%
mutate(ComparisonCategory = case_when(
grepl("Before|After", Comparison) ~ "Order",
grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
TRUE ~ NA_character_
)) %>%
mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))
# Merge the datasets based on 'SubID'
merged_data <- counting_summary %>%
inner_join(task_summary, by = "SubID")
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask)) +
geom_point(color = "blue", size = 3) +  # Scatter plot points
geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 2), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 2), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
legend.position = "none"
)
# Calculate the overall counting score
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarize(PropCorrCounting = mean(accuracy))
# Calculate the overall task score
task_summary <- task_data %>%
filter(Include == 1) %>%
mutate(ComparisonCategory = case_when(
grepl("Before|After", Comparison) ~ "Order",
grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
TRUE ~ NA_character_
)) %>%
mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))
# Merge the datasets based on 'SubID'
merged_data <- counting_summary %>%
inner_join(task_summary, by = "SubID")
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask)) +
geom_point(color = "blue", size = 3) +  # Scatter plot points
geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
legend.position = "none"
)
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask, color = ComparisonCategory)) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = FALSE) +
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Create separate faceted plots for Order and Magnitude tasks
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask, color = ComparisonCategory)) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = FALSE) +
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
) +
facet_wrap(~ComparisonCategory)
sameside_data <- task_summary %>%
filter(SideCategory == "Same")
# Create a data visualization to communicate the pattern
ggplot(same_side_data, aes(x = TrialCategory, y = PropCorrYNTask)) +
geom_boxplot(fill = "lightblue", color = "blue", width = 0.6, outlier.shape = NA) +
geom_jitter(position = position_jitter(width = 0.2), color = "blue", size = 3) +
stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
labs(
title = "Task Performance Pattern for Same Side Trials",
x = "Trial Type",
y = "Proportion Correct (Mean)"
) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
#this is just to give you an example of the code chunk header above, which is only necessary if you're submitting an assignment with code that won't run.
#for example, you might want to do that if you've made some progress on a problem, but aren't able to fully complete it. Rather than submitting nothing, submit what you've done so far.
library(tidyverse)
counting <- read.csv("BABSYN_counting_tidy.csv")
task_data <- read.csv("BABSYN_YNtask_tidy.csv")
counting_summary <- counting %>%
filter(Include == 1) %>%  # Filter data for children with Include variable equal to 1
group_by(SubID) %>%
summarize(PropCorrCounting = mean(accuracy))
task_summary <- task_data %>%
filter(Include == 1) %>%
mutate(ComparisonCategory = case_when(
grepl("Before|After", Comparison) ~ "Order",
grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
TRUE ~ NA_character_
)) %>%
mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))
glimpse(task_summary)
combined_summary <- counting_summary %>%
inner_join(task_summary, by = "SubID")
# PropCorrCounting repeats because it presents the proportion of correct responses in the counting task-- remains constant for that participant.
# Calculate the overall counting score
counting_summary <- counting %>%
filter(Include == 1) %>%
group_by(SubID) %>%
summarize(PropCorrCounting = mean(accuracy))
# Calculate the overall task score
task_summary <- task_data %>%
filter(Include == 1) %>%
mutate(ComparisonCategory = case_when(
grepl("Before|After", Comparison) ~ "Order",
grepl("Smaller|Bigger", Comparison) ~ "Magnitude",
TRUE ~ NA_character_
)) %>%
mutate(SideCategory = ifelse(Side == "same", "Same", "Opposite")) %>%
mutate(TrialCategory = ifelse(grepl("consecutive", TrialType), "Consecutive", "Non-consecutive")) %>%
group_by(SubID, ComparisonCategory, SideCategory, TrialCategory) %>%
summarise(PropCorrYNTask = mean(Response.corr, na.rm = TRUE))
# Merge the datasets based on 'SubID'
merged_data <- counting_summary %>%
inner_join(task_summary, by = "SubID")
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask)) +
geom_point(color = "blue", size = 3) +  # Scatter plot points
geom_smooth(method = "lm", color = "red", se = FALSE) +  # Linear regression line
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
legend.position = "none"
)
# Create a scatter plot to explore the hypothesis
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask, color = ComparisonCategory)) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = FALSE) +
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Create separate faceted plots for Order and Magnitude tasks
ggplot(merged_data, aes(x = PropCorrCounting, y = PropCorrYNTask, color = ComparisonCategory)) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = FALSE) +
labs(
title = "Correlation Between Counting Score and Task Score",
x = "Overall Counting Score",
y = "Overall Task Score"
) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
) +
facet_wrap(~ComparisonCategory)
sameside_data <- task_summary %>%
filter(SideCategory == "Same")
# Create a data visualization to communicate the pattern
ggplot(same_side_data, aes(x = TrialCategory, y = PropCorrYNTask)) +
geom_boxplot(fill = "lightblue", color = "blue", width = 0.6, outlier.shape = NA) +
geom_jitter(position = position_jitter(width = 0.2), color = "blue", size = 3) +
stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
labs(
title = "Task Performance Pattern for Same Side Trials",
x = "Trial Type",
y = "Proportion Correct (Mean)"
) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
sameside_data <- task_summary %>%
filter(SideCategory == "Same")
# Create a data visualization to communicate the pattern
ggplot(same_side_data, aes(x = TrialCategory, y = PropCorrYNTask)) +
geom_boxplot(fill = "lightblue", color = "blue", width = 0.6, outlier.shape = NA) +
geom_jitter(position = position_jitter(width = 0.2), color = "blue", size = 3) +
stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
labs(
title = "Task Performance Pattern for Same Side Trials",
x = "Trial Type",
y = "Proportion Correct (Mean)"
) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
sameside_data <- task_summary %>%
filter(SideCategory == "Same")
# Create a data visualization to communicate the pattern
ggplot(sameside_data, aes(x = TrialCategory, y = PropCorrYNTask)) +
geom_boxplot(fill = "lightblue", color = "blue", width = 0.6, outlier.shape = NA) +
geom_jitter(position = position_jitter(width = 0.2), color = "blue", size = 3) +
stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
labs(
title = "Task Performance Pattern for Same Side Trials",
x = "Trial Type",
y = "Proportion Correct (Mean)"
) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
theme_minimal() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
library(tidyverse)
load("C:/Users/stanl/OneDrive/Documents/GitHub/412/FinalProject/ufc_stats.rda")
View(ufc_stats)
View(ufc_stats)
View(ufc_stats)
plot(cars)
x <- 2+2
help()
2+2
make_negative <- function(x){
abs(x)*(-1)
}
make_negative(-3)
favenumber <- 8
?sd
sd(1:2)^2
(7*8) <= make_negative(56)|| TRUE
my_first_vector <- c(1, 2, 3)
my_second_vector <- c(3, 4, 5)
my_second_vector
my_list <- list(my_first_vector, my_second_vector)
my_list
as.data.frame(my_list)
x <- 10
if (x < 10){
print("low")
}else if (x>=10 && x<=20){
print("medium")
}else{
print("high")
}
names <- c("John", "joe", "Stan")
for(name in names){
message <- paste("Hi", names)
print(message)
}
library(tidyverse)
my_numbers <- c(1,2,3,4,5,8,9,10)
mean(my_numbers)
glimpse(ChickWeight)
ChickWeight %>%
select(age_days= Time, weight_gm= weight) %>%  #%>%--just means "and then"
head( n = 3)
chick_class <- ChickWeight %>%
select(chick_id = Chick, diet = Diet, age_days = Time, weight_gm = weight)
chick_class %>%
arrange(chick_id) %>%
head()
chick_class %>%
mutate(new_column = "value") %>%
head(n = 3)
chick_class %>%
mutate(weight_per_day = weight_gm/age_days) %>%
head(n = 3)
chick_class %>%
mutate(session = case_when(age_days == 0 ~ "birth",
age_days == 20 ~ "last1",
age_days == 21 ~ "last2",
TRUE           ~ as.character(age_days)))
chick_class %>%
mutate(weight_lbs = weight_gm/453.6) %>%
group_by(diet)%>%
summarise(n_obs = n(), mean_wgt_gm = mean(weight_gm))
?pivot_longer
billboard %>%
pivot_longer(cols= starts_with("wk"), names_to = "week", values_to = "rank", names_transform = list(week = parse_number)) #or names_prefix = "wk"
billboard %>%
separate(col =date.entered, into= c("year", "month", "day"), sep = "-")
billboard %>%
separate(col =date.entered, into= c("year", NA, NA), sep = "-")
?fish_encounters
fish_encounters %>%
filter(is.na(seen) == TRUE)
fish_encounters %>%
group_by(seen) %>%
count()
fish_encounters %>%
complete(fish, station)
fish_encounters %>%
group_by(station) %>%
count()
fish_complete <- fish_encounters %>%
complete(fish, station)
fish_complete %>%
group_by(station) %>%
count()
fish_encounters %>%
complete(fish, station, fill = list(seen = 0)) %>%
group_by(seen) %>%
count()
fish_encounters %>%
complete(fish, station) %>%
replace_na(list(seen=0))
?read_csv
billboard %>%
write_csv("billboard_data.csv")
billboard_edited <- read_csv("billboard_data.csv", name_repair = "unique")
billboard_edited
billboard_edited %>%
group_by("wk66") %>%
count()
billboard_edited %>%
select(-date.entered...3, date.entered = date.entered...4)
install.packages("papaja")
?papaja
View(ufc_stats)
library(tidyverse)
library("papaja")
r_refs("r-references.bib")
ChickWeight %>%
ggplot(aes( y= weight, x= Time, group = Chick)) +
geom_line()
ChickWeight %>%
ggplot(aes( y= weight, x= Time, group = Chick, color = Diet)) +
geom_line()
vec_mode <- function(x){
grouped_tibble <- years_in_college %>%
as.tibble %>%
group_by(value)%>%
count() %>%
max_count <- max(grouped_tibble$n)
grouped_tibble %>%
filter(n == max_count)%>%
select(value) %>%
pull()
}
ChickWeight %>%
ggplot(aes( y= weight, x= Time, group = Chick, color = Diet)) +
geom_line()
library(tidyverse)
if(!"tinytex" %in% rownames(installed.packages())) install.packages("tinytex")
tinytex::install_tinytex()
initexmf --set-config-value [MPM]AutoInstall=1
tinytex::tlmgr_update()
tinytex::tlmgr_repo("https://ctan.math.illinois.edu/systems/texlive/tlnet")
library("papaja")
r_refs("r-references.bib")
vec_mode <- function(x) {
group_tibble <- as.tibble(x) %>%
group_by(value) %>%
count()
max_count <- max(group_tibble$n)
result <- group_tibble %>%
filter(n == max_count) %>%
select(value) %>%
pull()
return(result)
}
years_in_college <- c(4, 4, 4, 4, 3, 4, 2, 3, 3, 4, 4)
vec_mode(years_in_college)
library(tidyverse)
View(sameside_data)
library("papaja")
r_refs("r-references.bib")
ChickWeight %>%
ggplot(aes(y= weight, x= Time, group = Chick, color = Diet)) +
geom_line()+
theme(
panel.grid.major.x = element_blank()
)
ChickWeight %>%
group_by(Diet, Time)%>%
summarise(mean_weight = mean(weight)) %>%
pivot_wider(values_from = mean_weight, names_from = Diet)%>%
knitr::kable(digits = 2, align= "c")
